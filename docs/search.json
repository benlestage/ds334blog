[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/test/index.html",
    "href": "posts/test/index.html",
    "title": "Test Post",
    "section": "",
    "text": "library(palmerpenguins)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(data = penguins, aes(x = bill_length_mm)) + \n  geom_histogram(colour = \"black\", fill = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Blog Post 1/index.html",
    "href": "posts/Blog Post 1/index.html",
    "title": "Test Post",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/benlestage/Desktop/ds334blog\n\ncert_df &lt;- read_csv(here(\"data/FinalProjectData234.csv\"))\n\nRows: 121 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): CASE\ndbl (9): Cert, Reverse, dissent, con issue, USAParty, Cues, Court, direction...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncert_df &lt;- cert_df |&gt; slice(1:112)"
  },
  {
    "objectID": "posts/Blog Post 1/index.html#introduction",
    "href": "posts/Blog Post 1/index.html#introduction",
    "title": "Test Post",
    "section": "Introduction",
    "text": "Introduction\nFor this blog post I will be working with a data set that I collected for a my Government Major Seminar. This data is a random sample of 112 cases from the Supreme Court’s October Term 2020. The variables I am most interested in are Cert (whether the case was granted Certiorari), Cues (the number of cues that justices look at when deciding to grant cert), and Court (Average JCS score which is a measure of judicial ideology of the Justices who read the case). I am most interested at looking at the difference in rates of Cert votes for different Court Ideologies and numbers of cues. This is interesting because even though there is only one term represented, there are two values for the Court’s average JCS score as Justice Barrett joined the court in the middle of the term and her addition made the court slightly less conservative.\nIs there a perceivable difference in rates of Cert grants between cases that Justice Barrett decided on and how does the number of cues present in a case affect this difference?\nThis data was hand collected and coded by myself in November of 2022. Using guidance from well researched coding methods for Supreme Court data, I personally read all 112 cases and hand coded the variables accordingly.\nDescription of relevant variables:\nCert - Whether the case was granted Certiorari (read and decided on by Supreme Court), coded as 1 = Yes, 0 = No\nCues - Count of the number of cues present in a case, cues are defined as things Justices look for in a case that typically increase the chances of a cert vote. I selected the 4 most important cues which was decided through previous research (Reversal in the lower courts, Dissent in the lower court, Whether the case contains a Constitutional Issue, and whether US is a party in the case)\nCourt - Average JCS Score of the Court. JCS Scores are a well researched method of coding Judicial Ideology. -1 entirely liberal, 0 entirely neutral, 1 entirely conservative.\n\nVisualizations\npenguins_sum &lt;- penguins |&gt; group_by(species, year) |&gt; summarise(n_penguins = n()) |&gt; mutate(year = factor(year))\n\ncert_longer &lt;- cert_df |&gt; pivot_longer(c(3:6), names_to = \"cue\", values_to = \"presence\") \n\ncert_df&lt;- cert_df |&gt; mutate(court = factor(Court)) |&gt; mutate(cert = factor(Cert))\n\nggplot(data = cert_df, aes(x = court, fill = cert)) +\n  geom_bar(position = \"dodge\") +\n  coord_flip() +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\nThis side by side bar plot demonstrates the difference in the number of cases granted and denied cert based on whether Justice Barrett was deciding on the case. The bars under 0.11 represent the cases where Justice Barrett did not decide and the bars under 0.099 represent the cases where Justice Barrett did decide. As demonstrated by the plot, the sample sizes are not the same for these groups which shows that Barrett decided on more cases than not this Term. While this is true, the relationship between cert grants and denies is still demonstrated by the plot. It appears from this plot that the court was far more likely to grant cert when Barrett was deciding despite the larger sample size.\n\ncert_df &lt;- cert_df |&gt; mutate(cues = factor(Cues))\n\nggplot(data = cert_df, aes(x = cues, fill = cert)) +\n  geom_bar(position = \"dodge\") +\n  coord_flip() + \n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\nThis side by side bar plot demonstrates the same things as the previous one however it instead groups the data by the number of cues rather than whether Justice Barrett decided on the case. The results shown in this plot are not surprising in the least and do a good job illustrating the relationship between Cert grants and the number of cues present in a case. Unsurprisingly, as the number of cues in a case increase, they are more likely to be granted Cert. Cases with one cue are an interesting subset to look at because this is the tipping point where cases begin to be more likely to be granted Cert. However, interestingly they are only slightly more likely to be granted Cert with only one cue.\nThis presents an interesting question of whether certain cues are more important than others.\n\nggplot(data = cert_longer, aes(x = cue, y = presence, fill = factor(Cert))) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\nThis plot provides an answer to this secondary question, as it appears that the case containing a Constitutional Issue and the case being reversed in the lower court to be the most important cues given they have high proportions of grants vs denies. Interestingly Dissent appears to be extremely important as it has a very good grant to deny ratio, however it is hard to speak on this definitively given the sample size of cases with lower court dissents is so low.\n\n\nConclusion\nThere were a few limitations that I encountered with this data. Primarily, this data was collected from only one Supreme Court term and therefore represents only a small sample of Terms and Courts. This makes it difficult to generalize any findings to the Court at large and only allows me to draw conclusions on this specific Term. However, because this data is so reliant on the JCS score of this specific Court, much of the findings can probably be generalized until the Court loses or gains any new members. With more time, I would like to extend this dataset to incorporate more cases and Courts, so there will be a larger sample size and therefore more concrete conclusions can be drawn."
  },
  {
    "objectID": "posts/Blog Post 1/index.html#connections-to-class-ideas",
    "href": "posts/Blog Post 1/index.html#connections-to-class-ideas",
    "title": "Test Post",
    "section": "Connections to Class Ideas",
    "text": "Connections to Class Ideas\nMy visualizations connect to class in a few ways. First I decided to use stacked and side-by-side bar plots because I was looking primarily at connections between categorical variables. Because these are easier to read, generally speaking, than a heatmap and I did not have too many categories these seemed like the best option. Along with this, I was able to use distinct colour scales because none of my variables were continuous. I utilized coord flips in order to place quantitative variables on the x-axis which also imporves the readability of my plots."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ds334blog",
    "section": "",
    "text": "Blog Post 2\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2024\n\n\nBen LeStage\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 3\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2024\n\n\nBen LeStage\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 1\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2024\n\n\nBen LeStage\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Blog Post 2/index.html",
    "href": "posts/Blog Post 2/index.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "library(tidyverse)\n\n\ntuesdata &lt;- tidytuesdayR::tt_load('2024-01-09')\n\n\n    Downloading file 1 of 4: `canada_births_1991_2022.csv`\n    Downloading file 2 of 4: `nhl_player_births.csv`\n    Downloading file 3 of 4: `nhl_rosters.csv`\n    Downloading file 4 of 4: `nhl_teams.csv`\n\ncanada_births_1991_2022 &lt;- tuesdata$canada_births_1991_2022\nnhl_player_births &lt;- tuesdata$nhl_player_births\nnhl_rosters &lt;- tuesdata$nhl_rosters\nnhl_teams &lt;- tuesdata$nhl_teams\n\n\nIntroduction\nFor this post, I will be working with the Canadian Hockey Player Birth Months data from tidytuesday.\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-01-09/readme.md\nSpecifically, from this data I will be using the nhl_rosters data frame. This data set consists of 54,873 nhl players and the teams they played for.\nIn this data frame I will be mainly looking at sweater_number, position_code, and shoots_catches. With this, I will be attempting to answer a couple questions and explore a few relationships in the data. My main question of interest consists of looking at the relationship between sweater_number and position_code. I am interested in this question because in my hockey career I have noticed a trend where Defensemen tend to wear single-didget numbers more often and I am curious as to see whether this trend that I have noticed is consistent in the NHL. Along with this, I will be looking at the relationship between shoots_catches and position_code to see if certain handedness is favored at specific positions in the NHL. I will also be looking at the relationship between shoots_catches and team_code to see if certain teams favor players of certain handedness.\n\n\nPrimaary Visualizations\n\nggplot(data = nhl_rosters, aes(x = sweater_number, fill = position_code)) +\n  geom_bar() +\n  coord_flip() +\n  scale_fill_viridis_d()\n\nWarning: Removed 149 rows containing non-finite values (`stat_count()`).\n\n\n\n\n\nThis barplot demonstrates the trend in jersey numbers by position. As can be seen from the plot, the large majority of players throughout nhl history have worn jersey numbers that tend to be lower, regardless of position. This can probably be explained by the fact that in hockey, until relatively recently players only wore numbers between 1 and 30. Also demonstrated by the plot is that fact that numbers 1 and 30 tned to be worn by goalies rather than skaters. Again this speaks to the trend when players wore numbers between 1 and 30 with goalies typically wearing the jersey numbers 1 and 30 and the rest of the skaters wore numbers in between. Along with this, my hunch was correct that lower jersey numbers(specificially single didget numbers) tend to be worn by defencemen rather than forewards or goalies which is also demonstrated by the plot.\n\nggplot(data = nhl_rosters, aes(x = shoots_catches, fill = position_code)) +\n  geom_bar(position = \"dodge\") +\n  coord_flip() +\n  scale_fill_viridis_d()\n\n\n\n\nThis barplot demonstrates some other interesting trends in NHL data. As can be seen from the plot, the NHL tends to be dominated by left-handed players which might seem surprising at first glance. However, in hockey players are coached to use their dominant hand on the top of the stick. For a right-handed person this would mean their right hand would be on the top of the stick which would make them a player that shoots left. This makes the barplot make more sense in that right handed people would be left-handed shooters and since there are more right handed people in the world, this trend makes sense. I was also surprised by the breakdown of handedness by position. Unsurprisingly, right handed shooters tend to play right wing more than they play left wing, this is also the case for left handed players playing left wing. Unsurprisingly, defensemen do not have as clear of a trend. This might make sense in the fact that defense is not broken up into left and right in the same way that the foreward position is. There are more left handed defenseman but agian this most likely just demonstrates the fact that there are more right hadned people in the world.\n\nggplot(data = nhl_rosters, aes(x = team_code, fill = shoots_catches)) +\n  geom_bar() +\n  coord_flip() + \n  scale_fill_viridis_d()\n\n\n\n\nThis plot demonstrates a similar trend to the previous barplot. Again, this plot shows that the majority of players in the NHL shoot left, this can again be explained by the fact that the majority of people in the world are right handed. More interestingly however is the fact that it appears that some teams have a higher percentage of players that shoot right. For example, Toronto, Montreal, Detroit, Chicago, and Boston all have had more right handed players throughout their history than other teams. While this is an interesting discovery, this could also just be due to the difference in sample size. All of these teams are included in the original six NHL teams so they have been around the longest and therefore have had more players in their teams’ histories.\n\n\nConclusion and Wrap Up\nOverall, I do not see many flaws with my approach to analyzing this data. Sample size is not an issue given that this data frame includes every player in NHL history. Along with this, I was not limited by any of the data points or in the organization of the data when making my visualizations. There were some missing data points for handedness, however I decided to include them as it gives an interesting perspective probably from a time when handedness of players was not recorded.\n\n\nConnections to class Ideas\nBecause all of my questions of interest were based around two categorical variables, I decieded to use stacked and side-by-side bar plots. I would have prefered to use side by side bar plots for each question of interest because it better allows someone to see the real count, however for the questions involving jersey numbers and teams there were too many categories on the x-axis making the plots far too messy."
  },
  {
    "objectID": "posts/Blog Post 3/index.html",
    "href": "posts/Blog Post 3/index.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "library(tidyverse)\n\nnyt_titles &lt;- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_titles.tsv')\nnyt_full &lt;- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_full.tsv')"
  },
  {
    "objectID": "posts/Blog Post 3/index.html#introduction",
    "href": "posts/Blog Post 3/index.html#introduction",
    "title": "Blog Post 3",
    "section": "Introduction",
    "text": "Introduction\nFor this post, I will be using the NYT best sellers data set which consists of 7,431 books that have been on the NYT best sellers list. I retrieved this data from Tidy Tuesday week 19 2022.\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-05-10/readme.md\nMy primary interest with this data is to fit and visualize a model to predict the number of weeks a book was on the list based on what rank the book debuted at. I will also fit and visualize a model to predict the number of weeks a book was on the list based on the book’s best rank. I will compare these models."
  },
  {
    "objectID": "posts/Blog Post 3/index.html#primary-visualizations",
    "href": "posts/Blog Post 3/index.html#primary-visualizations",
    "title": "Blog Post 3",
    "section": "Primary Visualizations",
    "text": "Primary Visualizations\n\nlibrary(broom)\nlibrary(modelr)\n\n\nAttaching package: 'modelr'\n\n\nThe following object is masked from 'package:broom':\n\n    bootstrap\n\nmod_rank &lt;- lm(total_weeks ~ debut_rank, data = nyt_titles)\nmod_rank |&gt; tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  8.13        0.259   31.3     1.93e-202\n2 debut_rank  -0.000155    0.0284  -0.00545 9.96e-  1\n\ngrid &lt;- nyt_titles |&gt;\n  data_grid(\n    debut_rank = seq_range(debut_rank, n = 6)\n  )\n\naug_rank &lt;- augment(mod_rank, newdata = grid, \n                    interval = \"confidence\")\n\n\nggplot(data = nyt_titles, aes(x = debut_rank, y = total_weeks)) +\n  geom_point() +\n  geom_line(data = aug_rank, aes(x = debut_rank, y = .fitted), \n            colour = \"blue\", linewidth = 1.2)\n\n\n\n\nBased on this model and visualization, it appears as though debut rank is not a strong predictor to see how long a book will remain on the best sellers list. There is a slightly positive relationship, meaning that the lower a book debuted on the list, the more weeks it is likely to remain on the list. This is somewhat surprising given one might expect that a higher debuting book to remain on the list for longer. However, this correlation is not very strong at all and most likely means there is no real relationship between debut rank and number of weeks on the list.\n\nmod_rank_2 &lt;- lm(total_weeks ~ best_rank, data = nyt_titles)\nmod_rank_2 |&gt; tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)    15.8     0.211       74.9       0\n2 best_rank      -1.11    0.0254     -43.5       0\n\ngrid &lt;- nyt_titles |&gt;\n  data_grid(\n    best_rank = seq_range(best_rank, n = 6)\n  )\n\naug_rank &lt;- augment(mod_rank_2, newdata = grid,\n                    interval = \"confidence\")\n\n\nggplot(data = nyt_titles, aes(x = best_rank, y = total_weeks)) +\n  geom_point() +\n  geom_line(data = aug_rank, aes(x = best_rank, y = .fitted),\n            colour = \"blue\", linewidth = 1.2)\n\n\n\n\nThe relationship between these two variables seems to be far more visible based on this plot. There is a clear negative relationship between the best rank a book received and the number of weeks the book was on the list. This relationship tends to make sense, as a book that spent more time on the list would have more of an opportunity to receive a higher rank. This relationship is much stronger than that between debut rank and total weeks on the list.\n\nConclusion and Wrap up\nI do not feel as though there are flaws in how I analyzed this data, I followed the steps for visualizing a model that we went over in class. However, I feel that if there had been more variables, such as the books genre I would have been able to visualize a more complex model. Had there been a categorical variable such as genre I would have been able to compare the relationships between genres, utilizing different colours to show the difference in the relationships between genres."
  }
]